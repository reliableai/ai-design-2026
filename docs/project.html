<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Project - Designing Large Scale AI Systems</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <!-- Header loaded dynamically -->

  <main>
    <h1>Course Project</h1>
    <p class="text-muted">Build and evaluate a large-scale AI system (Weeks 6-12)</p>

    <h2>Overview</h2>
    <p>
      The course project is the capstone experience of this course. You'll apply everything
      you've learned to design, implement, and rigorously evaluate an AI-powered system.
      Projects can be done individually or in teams of two.
    </p>

    <h2>Track Options</h2>
    <div class="card-grid">
      <div class="card">
        <h3>Track A: Class System</h3>
        <p>
          Work on a shared class project with a well-defined scope and requirements.
          This option provides more structure and allows for peer comparison.
        </p>
        <ul>
          <li>Pre-defined problem space</li>
          <li>Shared baseline components</li>
          <li>Focus on evaluation and optimization</li>
        </ul>
      </div>
      <div class="card">
        <h3>Track B: Capstone</h3>
        <p>
          Propose your own project idea. This option offers more freedom but requires
          a strong problem statement and feasibility assessment.
        </p>
        <ul>
          <li>Custom problem definition</li>
          <li>Full system design responsibility</li>
          <li>Must be approved by instructor</li>
        </ul>
      </div>
    </div>

    <h2>Project Requirements</h2>

    <h3>System Requirements</h3>
    <ul>
      <li>Functional AI-powered application with clear use case</li>
      <li>Integration of agents, tools, and/or memory systems</li>
      <li>Appropriate error handling and logging</li>
      <li>Basic observability (metrics, logs)</li>
      <li>Safety considerations and guardrails where appropriate</li>
    </ul>

    <h3>Evaluation Requirements</h3>
    <ul>
      <li><strong>Golden Dataset:</strong> Curated test set with ground truth labels</li>
      <li><strong>Metrics:</strong> Well-justified selection of evaluation metrics</li>
      <li><strong>Experiments:</strong> At least one ablation study or comparative experiment</li>
      <li><strong>Error Analysis:</strong> Systematic categorization of failure modes</li>
      <li><strong>Uncertainty:</strong> Confidence intervals or other uncertainty measures</li>
    </ul>

    <h2>Deliverables</h2>

    <h3>Week 6: Project Specification v1</h3>
    <ul>
      <li>Problem statement and motivation</li>
      <li>High-level architecture sketch</li>
      <li>Initial evaluation plan</li>
      <li>Team composition and responsibilities</li>
    </ul>

    <h3>Week 7: Project Review #1</h3>
    <ul>
      <li>Refined problem statement and scope</li>
      <li>Detailed architecture diagram</li>
      <li>Golden dataset status and plan</li>
      <li>Milestone plan for Weeks 8-10</li>
    </ul>

    <h3>Week 9: Mid-Project Presentation</h3>
    <ul>
      <li>10-12 minute presentation</li>
      <li>Live or recorded demo of current system</li>
      <li>Architecture overview</li>
      <li>Early evaluation results</li>
      <li>Open risks and unknowns</li>
    </ul>

    <h3>Week 12: Final Deliverables</h3>

    <h4>Final Presentation (Graded)</h4>
    <ul>
      <li>System demo</li>
      <li>Design choices and alternatives considered</li>
      <li>Evaluation framework and main results</li>
      <li>Limitations and future work</li>
      <li>Q&A session</li>
    </ul>

    <h4>Final Report</h4>
    <ul>
      <li>Introduction and motivation</li>
      <li>System architecture and design decisions</li>
      <li>Implementation details</li>
      <li>Evaluation methodology</li>
      <li>Results and analysis</li>
      <li>Error taxonomy with examples</li>
      <li>Conclusions and lessons learned</li>
    </ul>

    <h4>Code Repository</h4>
    <ul>
      <li>Clean, documented source code</li>
      <li>README with setup instructions</li>
      <li>Evaluation scripts and golden dataset</li>
      <li>Results and logs from evaluation runs</li>
    </ul>

    <h2>Timeline</h2>
    <table>
      <thead>
        <tr>
          <th>Week</th>
          <th>Activity</th>
          <th>Focus</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>6</strong></td>
          <td>Project Kick-off (L12)</td>
          <td>Track selection, team formation, Project Spec v1</td>
        </tr>
        <tr>
          <td><strong>7</strong></td>
          <td>Project Review #1 (L14)</td>
          <td>Architecture, evaluation plan, milestone planning</td>
        </tr>
        <tr>
          <td><strong>8</strong></td>
          <td>Working Sessions (L15-16)</td>
          <td>Implementation, first evaluation run</td>
        </tr>
        <tr>
          <td><strong>9</strong></td>
          <td>Mid-Project Demo (L17)</td>
          <td>Internal presentation, design clinic</td>
        </tr>
        <tr>
          <td><strong>10</strong></td>
          <td>Final Push (L19-20)</td>
          <td>Integration, hardening, final evaluation runs</td>
        </tr>
        <tr>
          <td><strong>11</strong></td>
          <td>Results Review (L21-22)</td>
          <td>Storytelling, presentation rehearsals</td>
        </tr>
        <tr>
          <td><strong>12</strong></td>
          <td>Final Presentations (L23-24)</td>
          <td>Graded presentations, retrospective</td>
        </tr>
      </tbody>
    </table>

    <h2>Team Formation</h2>
    <div class="card">
      <h3>Guidelines</h3>
      <ul>
        <li>Teams of 1-2 students</li>
        <li>Both team members must contribute equally</li>
        <li>Define clear responsibilities early</li>
        <li>Track A and Track B teams can be mixed in review sessions</li>
      </ul>

      <h3>Responsibilities</h3>
      <p>For 2-person teams, consider dividing work along these lines:</p>
      <ul>
        <li><strong>System Lead:</strong> Architecture, implementation, integration</li>
        <li><strong>Evaluation Lead:</strong> Golden dataset, metrics, experiments, analysis</li>
      </ul>
      <p class="text-muted text-small">Both members should understand the full system and be able to present any part.</p>
    </div>

    <h2>Grading Rubric</h2>
    <p>
      For detailed grading criteria, see the <a href="grading/grading.md">full grading rubric</a>.
    </p>

    <h2>Resources</h2>
    <div class="card">
      <h3>Getting Help</h3>
      <ul>
        <li><strong>Office Hours:</strong> Right after each class</li>
        <li><strong>Working Sessions:</strong> Weeks 8 and 10 are dedicated project time</li>
        <li><strong>Design Clinics:</strong> Week 9 breakout tables for specific topics</li>
        <li><strong>Peer Reviews:</strong> Feedback from other teams throughout</li>
      </ul>
    </div>

    <p class="mt-3">
      <a href="assessments.html" class="btn-secondary btn">Back to Assessments</a>
    </p>
  </main>

  <footer>
    <p>Designing Large Scale AI Systems &middot; Spring 2026</p>
  </footer>

  <script src="scripts.js"></script>
</body>
</html>
